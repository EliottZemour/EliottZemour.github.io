---
title: "Effective Unbiased Membership Inference against Image and Language Models"
layout: post
date: 2022-01-21 22:10
tag: mia-nlp
image: /assets/images/EPFL_logo.png
headerImage: false
projects: true
hidden: true # don't count this post in blog pagination
description: ""
category: project
author: eliott
externalLink: false
---

This is a semester project carried out during my master studies in computational science and engineering at EPFL. 
* Duration: 5 months (September 2021 - January 2022)
* Supervisor: Bogdan Kulynych (Spring lab, EPFL) 


---
### Abstract
Membership inference attacks (MIAs) against machine learning aims to infer whether a data record was used to train a target model or not. When trained on sensitive and private data, vulnerability to MIA can be seen as a serious privacy threat.
In this report, we present an effective and unbiased way to evaluate MIA vulnerability and compare it to the shadow model approach considered until then. Membership inference is performed on various classification and language models under a black-box setting.
We investigate MIA performance as a function of the attack and the adversarial knowledge. We observe that the combination of adversary features is an efficient way of conducting membership inference, and threshold-based attacks often underperform compared to more complex methods. The attacks proposed are evaluated against models trained with differential privacy, and results show that this defense mechanism indeed mitigates the adversary success. Finally, we study membership inference on large language models (LMs) in the special case of fine-tuning. We consider a set of adversary features based on the perplexity measure, and demonstrate that fine-tuned LMs can be highly vulnerable to MIAs.

### About this project
* Differential privacy
* ~~Membership inference attacks~~
* Fine-tuning GPT-2
* 8 ECTS.